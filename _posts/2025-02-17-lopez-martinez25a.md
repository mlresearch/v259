---
title: Detecting sensitive medical responses in general purpose large language models
abstract: Generalist large language models (LLMs), not developed to do particular
  medical tasks, have achieved widespread use by the public. To avoid medical uses
  of these LLMs that have not been adequately tested and thus minimize any potential
  health risks, it is paramount that these models use adequate guardrails and safety
  measures. In this work, we propose a synthetic medical prompt generation method
  to evaluate generalist LLMs and enable red-teaming efforts. Using a commercial LLM
  and our dataset of synthetic user prompts, we illustrate how our methodology may
  used to identify responses for further evaluation and to assess whether guardrails
  are consistently implemented. Finally, we investigate the use of Flan-T5 in detecting
  LLM responses that offer unvetted medical advice and neglect to instruct users to
  consult with licensed professionals.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: lopez-martinez25a
month: 0
tex_title: Detecting sensitive medical responses in general purpose large language
  models
firstpage: 680
lastpage: 695
page: 680-695
order: 680
cycles: false
bibtex_author: Lopez-Martinez, Daniel and Bafna, Abhishek
author:
- given: Daniel
  family: Lopez-Martinez
- given: Abhishek
  family: Bafna
date: 2025-02-17
address:
container-title: Proceedings of the 4th Machine Learning for Health Symposium
volume: '259'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 2
  - 17
pdf: https://raw.githubusercontent.com/mlresearch/v259/main/assets/lopez-martinez25a/lopez-martinez25a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

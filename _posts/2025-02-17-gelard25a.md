---
title: 'BulkRNABert: Cancer prognosis from bulk RNA-seq based language models'
abstract: RNA sequencing (RNA-seq) has become a key technology in precision medicine,
  especially for cancer prognosis. However, the high dimensionality of such data may
  restrict classic statistical methods, thus raising the need to learn dense representations
  from them. Transformers models have exhibited capacities in providing representations
  for long sequences and thus are well suited for transcriptomics data. In this paper,
  we develop a pre-trained transformer-based language model through self-supervised
  learning using bulk RNA-seq from both non-cancer and cancer tissues, following BERT’s
  masking method. By probing learned embeddings from the model or using parameter-efficient
  fine-tuning, we then build downstream models for cancer-type classification and
  survival-time prediction. Leveraging the TCGA dataset, we demonstrate the performance
  of our method, BulkRNABert, on both tasks, with significant improvement compared
  to state-of-the-art methods in the pan-cancer setting for classification and survival
  analysis. We also show the transfer-learning capabilities of the model in the survival
  analysis setting on unseen cohorts.
software: https://github.com/instadeepai/multiomics-open-research
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: gelard25a
month: 0
tex_title: 'BulkRNABert: Cancer prognosis from bulk RNA-seq based language models'
firstpage: 384
lastpage: 400
page: 384-400
order: 384
cycles: false
bibtex_author: G{\'{e}}lard, Maxence and Richard, Guillaume and Pierrot, Thomas and
  Courn{\`{e}}de, Paul-Henry
author:
- given: Maxence
  family: Gélard
- given: Guillaume
  family: Richard
- given: Thomas
  family: Pierrot
- given: Paul-Henry
  family: Cournède
date: 2025-02-17
address:
container-title: Proceedings of the 4th Machine Learning for Health Symposium
volume: '259'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 2
  - 17
pdf: https://raw.githubusercontent.com/mlresearch/v259/main/assets/gelard25a/gelard25a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
